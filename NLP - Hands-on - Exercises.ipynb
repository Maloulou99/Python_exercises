{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, PorterStemmer, WordNetLemmatizer, SnowballStemmer\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bahar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bahar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\bahar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "The IMDb dataset consists of movie reviews from the IMDb website, each labeled with a sentiment score indicating whether the review is positive (1) or negative (0). This sentiment score helps in sentiment analysis tasks such as determining the overall opinion expressed in the review.\n",
    "\n",
    "The variable `data` comprises a list of dictionaries, each containing a `review` key with the movie's textual review and a `sentiment` key indicating whether the review is positive (1) or negative (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'review': 'I bought this DVD for £1 and now i realise why. The acting was the worst I\\'ve seen in a long time. The lighting and sound are shoddy at best. The plot makes little sense even when sober (WARNING: I don\\'t advise watching this film when sober.) This film feels like you\\'re watching the home movie of someone who doesn\\'t get out much. It really is a shame that all the very little money spent on this project went to such a waste, I look forward to seeing if any of those envoled still have a career, other than eva longoria who is the only \"star\" of this film that was apparently not hit with the bad acting stick. I\\'m sorry that none of this criticism seems constructive but I will say one thing to James Cahill, don\\'t try it again. In the words of squirlyem \"Its severely lacking in the good department\".',\n",
       "  'sentiment': 0},\n",
       " {'review': '\"Footlight Parade\" is just one of several wonderfully jaunty musicals that Warner Bros. produced in the early 1930\\'s to ward off the Depression. \"42nd Street\" and the Golddiggers series were also produced during this era, and they made literally, millions of Americans forget their troubles for a little while, and enjoy themselves.While most of the films produced had the great talents of Joan Blondell, Ruby Keeler, and Dick Powell, only Foolight Parade had the incomparable James Cagney. Almost ten years prior to his most well-known musical, \"Yankee Doodle Dandy\". Here he dances in that most original of dance styles, with his arms usually lowered at his side, and his legs doing all types of undulations and kicks. It\\'s easy to see that he is enjoying himself, and that makes us enjoy him all the more.While almost all of the musical sequences appear at the end of the film, they are well worth the wait. I believe that this film was made just prior to the installation of the production code, so some of the costumes and scenes are a bit risqué. But it\\'s all in fun.It doesn\\'t matter what the plot of the film is, just know that there are plenty of laughs and a superlative cast. Besides those already mentioned, Guy Kibbee is at his flustered best here.7 out of 10',\n",
       "  'sentiment': 1},\n",
       " {'review': 'When Hollywood is trying to grasp what an \"intelligent person\" is like, they fail so miserably, finding it hard putting words in the mouth of the purported \"genius\".Right, any genius walks around trying to rub in his superiority at every instance. Sure, they hang out in bars and pick fights \\x96 it\\'s not like they are (generalizing wildly) autistic nerds who never have a tan.Plus, if you are a genius you know all about Math and History and Politics and of course you\\'re constantly up to date with current events and a thorough analysis of them. Coz these things, like, all go together n stuff, y\\'know?Plus, you walk around with a smirk all the time. You are just a smug son of a you-know-what, that\\'s how it is, y\\'all. And of course you smoke, like someone who never smoked before, but you smoke coz it\\'s like cool n stuff, y\\'know. And you\\'re different. That is understood.And of course you can fight \\x96 you\\'re a bully. A bully who finds time to study 10.000 books whenever he doesn\\'t lift weights. And whenever he doesn\\'t smoke or drink beer because he follows a strict health regimen.And you date a 30-something college student \\x96 Minnie Driver. Well, I won\\'t even comment Matt Damon. Team America has hit the nail on the head already.This movie is a daydream of a Beavis & Butthead type student (in other words 95% of them): \"Yeah, that\\'s what I would be like if I was a genius.\" But stupid people and stupid authors in this case cannot imagine the lives of geniuses.',\n",
       "  'sentiment': 0},\n",
       " {'review': 'My father has worked with top secret information in the DIA before and he is the one who mentioned this movie to me. When I was a kid I would always ask him what would happen if he gave away secrets and he recommended this movie.In the movie it really puts 2, almost completely different FRIENDS! in a tangle they never really knew what the outcome would really be. The snowman, Daulton really cracked me up because the movie portrayed him as just some drug pusher that did not know what he was arguing about, and in the movie it seemed like he got the worst of everything. The falcon, Chris is just a guy that wanted to express his feelings on U.S government in a very radical view.For movie lovers this is a must see!!!',\n",
       "  'sentiment': 1},\n",
       " {'review': 'I first saw this film when I was in the 8th grade and I remember that it had a profound affect on me then. I saw in again about a year ago (I am now 29) and it still moved me in similar ways. This is a great movie that personifies the struggle of \"principle vs. pragmistism\". Voight\\'s character is the idealist teacher that won\\'t give in to any psuedo-racist leanings of the Superintendent, Mr. Skeffington. That story also personifies the struggle of how older people often resist change, and more specifically, cultural change. Often at the expense of children. When these battles finally come to a boil, Pat Conroy loses and pragmatism reigns triumphant. Or does it? The children that he has to leave are better off for knowing him, more exposed to the \"real\" world and to classical music. The other teacher at the school gained respect for him and he learned much about himself. A great film with a heart-breaking ending. I recomend that anyone who enjoyed the film to read the book, \"The Water is Wide\", by Pat Conroy. It will stay with you!',\n",
       "  'sentiment': 1}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load CSV data into a pandas DataFrame\n",
    "df = pd.read_csv('data/imdb_sentiment.csv')\n",
    "# Convert the DataFrame to a list of dictionaries\n",
    "data = df.to_dict(orient='records')\n",
    "# Print the 5 first records\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many reviews in total?\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive reviews: 481\n",
      "Number of negative reviews: 519\n"
     ]
    }
   ],
   "source": [
    "# TODO: How many positive and negative reviews?\n",
    "positive_count = 0\n",
    "negative_count = 0\n",
    "\n",
    "# Count positive and negative reviews\n",
    "for d in data:\n",
    "    if d['sentiment'] == 1:\n",
    "        positive_count += 1\n",
    "    elif d['sentiment'] == 0:\n",
    "        negative_count += 1\n",
    "\n",
    "print('Number of positive reviews:', positive_count)\n",
    "print('Number of negative reviews:', negative_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Text Preprocessing\n",
    "\n",
    "To simplify the reviews' text, apply preprocessing techniques:\n",
    "* **Tokenization**: Tokenize the text. It may be good to remove punctuation before or after the tokenization. You can use `string.punctuation` for this purpose, which contains a set of punctuation characters.\n",
    "* Either **stemming** or **lemmatization**: Choose one, not both, as using both could lead to redundancy; to decide, experiment with both and select the method that better suits your needs.\n",
    "* Remove **stop words**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    # Tokenize and remove punctuation\n",
    "    tokens = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_stop_words(tokens):\n",
    "    # Get the list over stopwords fra NLTK\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Filtre stopwords from the tokenlist\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(tokens):\n",
    "    # Initialiser one PorterStemmer\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    # Perform stemming on each token\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    return stemmed_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(tokens):\n",
    "    # Initialize WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # Lemmatize each token\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    return lemmatized_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    # Tokenize the text\n",
    "    tokens = tokenize(text.lower())\n",
    "    \n",
    "    # Remove punctuation and non-alphabetic characters\n",
    "    tokens = [re.sub(r'[^a-zA-Z]', '', token) for token in tokens if token.isalpha()]\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Stem or lemmatize the tokens\n",
    "    stemmer = PorterStemmer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    return stemmed_tokens, lemmatized_tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each element in the `data` list, process the review's text and store the result in a new key called `tokens`. It may take a few seconds to do all the processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process reviews' text\n",
    "for d in data:\n",
    "    review_text = d.get('review', '')  # Retrieve the review text, default to empty string if key is missing\n",
    "    tokens = process_text(review_text)  # Process the review text\n",
    "    d['tokens'] = tokens  # Assign the processed tokens to a new key 'tokens' in the dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Predict Positive or Negative Review\n",
    "\n",
    "Develop a simple rule-based model that predicts whether a review is positive or negative based on the total number of positive and negative words in the review.\n",
    "\n",
    "For example, if the review contains more positive words than negative words, predict that the review is positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define empty lists for negative and positive words\n",
    "negative_words = []\n",
    "positive_words = []\n",
    "\n",
    "# Add more words to the lists\n",
    "negative_words.extend([\n",
    "    'horrible',\n",
    "    'terrible',\n",
    "    'disappointing',\n",
    "    'bad'\n",
    "    'mad'\n",
    "])\n",
    "\n",
    "positive_words.extend([\n",
    "    'amazing',\n",
    "    'great',\n",
    "    'wonderful',\n",
    "    'awesome'\n",
    "    'nice'\n",
    "])\n",
    "\n",
    "# Apply stemming to the words\n",
    "negative_words = stem(negative_words)\n",
    "positive_words = stem(positive_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(tokens, words):\n",
    "    '''\n",
    "    Given a list of tokens and a list of words, return the total number of words\n",
    "    from the `words` list that appear in the `tokens` list.\n",
    "\n",
    "    For example:\n",
    "        tokens = ['the', 'good', 'amazing', 'movie', 'was', 'good']\n",
    "        words = ['good', 'amazing']\n",
    "        returns: 3 ('good' appears twice, and 'amazing' appears once in the `tokens` list)\n",
    "    '''\n",
    "   # Initialize a counter for the total number of words\n",
    "    count = 0\n",
    "    \n",
    "    # Iterate through each token in the tokens list\n",
    "    for token in tokens:\n",
    "        # If the token is in the words list, increment the count\n",
    "        if token in words:\n",
    "            count += 1\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict based on word count\n",
    "for d in data:\n",
    "    d['tokens'] = process_text(d['review'])\n",
    "\n",
    "# Predict based on word count\n",
    "for d in data:\n",
    "    n_positive_words = count_words(d['tokens'], positive_words)\n",
    "    n_negative_words = count_words(d['tokens'], negative_words)\n",
    "    \n",
    "    # Create a new key in `d` called 'prediction'\n",
    "    if n_positive_words > n_negative_words:\n",
    "        d['prediction'] = 1\n",
    "    elif n_negative_words > n_positive_words:\n",
    "        d['prediction'] = 0\n",
    "    else:\n",
    "        d['prediction'] = None\n",
    "\n",
    "# Predicted sentiments\n",
    "preds = [d['prediction'] for d in data]\n",
    "# Real sentiments\n",
    "real = [d['sentiment'] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown predictions: 100.00%\n",
      "Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Percentage of unknown predictions (i.e., when the prediction is None)\n",
    "print(f'Unknown predictions: {sum([1 for p in preds if p is None]) / len(preds):.2%}')\n",
    "\n",
    "# Accuracy of the known predictions, that is, the percentage of predictions that are correct\n",
    "acc = sum([1 for i in range(len(preds)) if preds[i] is not None and preds[i] == real[i]]) / len(preds)\n",
    "print(f'Accuracy: {acc:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Most Common Adjectives\n",
    "\n",
    "Get the most common adjectives in the positive and negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\bahar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists of tokens for positive and negative reviews\n",
    "positive_reviews = [d['tokens'] for d in data if d['sentiment'] == 1]\n",
    "negative_reviews = [d['tokens'] for d in data if d['sentiment'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag, word_tokenize\n",
    "from collections import Counter\n",
    "def get_most_common_adjectives(reviews, n=10):\n",
    "    adjs = []\n",
    "\n",
    "    # For each review, get the adjectives and add them to the `adjs` list\n",
    "    for r in reviews:\n",
    "        tokens = word_tokenize(r)\n",
    "        tagged_tokens = pos_tag(tokens)\n",
    "        for word, tag in tagged_tokens:\n",
    "            if tag.startswith('JJ'):  # JJ tags indicate adjectives\n",
    "                adjs.append(word)\n",
    "    \n",
    "    # Count the number of occurrences and return the most common adjectives\n",
    "    counts = Counter(adjs)\n",
    "    return counts.most_common(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common adjectives in positive reviews:\n",
      "[('[', 439), (\"'much\", 364), (\"'best\", 311), (\"'interest\", 109), (\"'actual\", 102), ('u', 93), (\"'american\", 91), (\"'touch\", 55), (\"'usual\", 46), (\"'rest\", 46)]\n",
      "\n",
      "Most common adjectives in negative reviews:\n",
      "[('[', 454), (\"'much\", 424), (\"'best\", 183), (\"'actual\", 126), (\"'interest\", 126), (\"'rest\", 108), (\"'american\", 98), ('u', 83), (\"'obvious\", 54), (\"'terrible\", 53)]\n"
     ]
    }
   ],
   "source": [
    "# Print the most common adjectives in positive and negative reviews\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def get_most_common_adjectives(reviews, n=10):\n",
    "    adjs = []\n",
    "\n",
    "    # For each review, get the adjectives and add them to the `adjs` list\n",
    "    for r in reviews:\n",
    "        # Ensure that each review is a string\n",
    "        review_text = str(r)\n",
    "        \n",
    "        tokens = word_tokenize(review_text)\n",
    "        tagged_tokens = pos_tag(tokens)\n",
    "        for word, tag in tagged_tokens:\n",
    "            if tag.startswith('JJ'):  # JJ tags indicate adjectives\n",
    "                adjs.append(word)\n",
    "    \n",
    "    # Count the number of occurrences and return the most common adjectives\n",
    "    counts = Counter(adjs)\n",
    "    return counts.most_common(n)\n",
    "\n",
    "pos_adjs = get_most_common_adjectives(positive_reviews)\n",
    "neg_adjs = get_most_common_adjectives(negative_reviews)\n",
    "\n",
    "print('Most common adjectives in positive reviews:')\n",
    "print(pos_adjs)\n",
    "print()\n",
    "print('Most common adjectives in negative reviews:')\n",
    "print(neg_adjs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Most Common Nouns\n",
    "\n",
    "Similar to the previous exercise, but instead of adjectives identify the most common nouns in positive and negative reviews.\n",
    "\n",
    "Are the nouns similar between positive and negative reviews? Why do you think this is the case?\n",
    "\n",
    "Considerations (there is no need to implement the following, it is just food for thought):\n",
    "- If there are substantial differences, it might be beneficial to incorporate these nouns into the `positive_words` and `negative_words` lists.\n",
    "- Conversely, if the nouns are largely consistent, it might be good and more efficient to exclude them from the tokenization process, as they may not significantly contribute to sentiment analysis.\n",
    "    - One option for facilitating this process is to use TF-IDF scoring, as tokens with lower scores are less informative due to their prevalence across both positive and negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common nouns in positive reviews:\n",
      "'film : 1819\n",
      "] : 962\n",
      "'movi : 790\n",
      "'movie : 790\n",
      "'time : 571\n",
      "'good : 563\n",
      "'great : 557\n",
      "'see : 478\n",
      "'get : 457\n",
      "'well : 436\n",
      "\n",
      "Most common nouns in negative reviews:\n",
      "'film : 1755\n",
      "'movi : 1143\n",
      "'movie : 1143\n",
      "] : 1038\n",
      "'good : 636\n",
      "'time : 622\n",
      "'bad : 622\n",
      "'get : 606\n",
      "'make : 559\n",
      "'see : 537\n"
     ]
    }
   ],
   "source": [
    "def get_most_common_nouns(reviews, n=10):\n",
    "    nouns = []\n",
    "\n",
    "    # For each review, get the nouns and add them to the `nouns` list\n",
    "    for review in reviews:\n",
    "        review_text = str(review)  # Ensure review is a string\n",
    "        tokens = word_tokenize(review_text)\n",
    "        tagged_tokens = pos_tag(tokens)\n",
    "        for word, tag in tagged_tokens:\n",
    "            if tag.startswith('NN'):  # NN tags indicate nouns\n",
    "                nouns.append(word)\n",
    "    \n",
    "    # Count the number of occurrences and return the most common nouns\n",
    "    counts = Counter(nouns)\n",
    "    return counts.most_common(n)\n",
    "\n",
    "# Get the most common nouns in positive and negative reviews\n",
    "pos_nouns = get_most_common_nouns(positive_reviews)\n",
    "neg_nouns = get_most_common_nouns(negative_reviews)\n",
    "\n",
    "# Print the most common nouns in positive reviews\n",
    "print('Most common nouns in positive reviews:')\n",
    "for noun, count in pos_nouns:\n",
    "    print(noun, ':', count)\n",
    "\n",
    "print()\n",
    "\n",
    "# Print the most common nouns in negative reviews\n",
    "print('Most common nouns in negative reviews:')\n",
    "for noun, count in neg_nouns:\n",
    "    print(noun, ':', count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: CountVectorizer\n",
    "\n",
    "Use the `CountVectorizer` class from scikit-learn to convert the reviews into a matrix of token counts, so each review is represented by a vector of the count of each token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [d['review'] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['00' '000' '007' ... 'émigrés' 'était' 'étoile']\n"
     ]
    }
   ],
   "source": [
    "# Create a CountVectorizer, fit and transform it based on the `reviews` list\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the CountVectorizer based on the reviews\n",
    "X = vectorizer.fit_transform(reviews)\n",
    "\n",
    "# Print the vocabulary learned by the CountVectorizer\n",
    "print(\"Vocabulary:\", vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Example\n",
    "\n",
    "Based on the previous vectorization based on `CountVectorizer`, we can use the vectors to train a machine learning model.\n",
    "\n",
    "For example, we can use the computed `vectors` as input features and the `sentiment` as the target variable (that is the variable we want to predict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate into training and test sets.\n",
    "\n",
    "- Training data is used for the model to learn from.\n",
    "- Test data is used to evaluate the trained model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Assuming you have 'reviews' as your list of reviews\n",
    "reviews = [d['review'] for d in data]\n",
    "\n",
    "# Initialize a TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the data to obtain TF-IDF vectors\n",
    "vectors = tfidf_vectorizer.fit_transform(reviews)\n",
    "\n",
    "# Split the vectors into training and test sets\n",
    "train_vectors = vectors[:700]\n",
    "test_vectors = vectors[700:]\n",
    "\n",
    "# Extract the sentiment labels from the data for both the training and test sets\n",
    "train_sentiments = [d['sentiment'] for d in data[:700]]\n",
    "test_sentiments = [d['sentiment'] for d in data[700:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the logistic regression model with the training data\n",
    "# This creates a mapping between the vectors and the sentiment labels\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(train_vectors, train_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model to predict the sentiment of the test data\n",
    "preds = lr.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.00%\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy of the model\n",
    "acc = sum([1 for i in range(len(preds)) if preds[i] == test_sentiments[i]]) / len(preds)\n",
    "print(f'Accuracy: {acc:.2%}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
